{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [this demo requires doom installed either officially or from gym-pool. Or simply use https://github.com/justheuristic/doomed_dqn]\n",
    "\n",
    "# This tutorial is will bring you through your first deep reinforcement learning model\n",
    "\n",
    "\n",
    "* Seaquest game as an example\n",
    "* Training a simple lasagne neural network for Q_learning objective\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=cpu\"\n",
      "env: OPENMP_NUM_THREADS=6\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=\"device=cpu\"\n",
    "\n",
    "%env OPENMP_NUM_THREADS=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "#game image will be resized from(96,128) to your image_size. \n",
    "#You may want a bigger image for your homework assignment IF you want a larger NN\n",
    "\n",
    "IMAGE_W,IMAGE_H = IMAGE_SIZE =(60,80)#(96,128)\n",
    "def preprocess(obs):\n",
    "    return (imresize(obs,IMAGE_SIZE).mean(-1)/255.)\n",
    "\n",
    "class Frameskipper:\n",
    "    def __init__(self,env,frameskip=4):\n",
    "        self.env=env\n",
    "        self.frameskip=frameskip\n",
    "    def step(self,action):\n",
    "        \n",
    "        total_reward = 0.\n",
    "        for i in range(self.frameskip):\n",
    "            obs,r,done,info = self.env.step(action)\n",
    "            total_reward += r\n",
    "            if done: break\n",
    "        \n",
    "        return obs,total_reward,done,info\n",
    "    def __getattr__(self,attr):\n",
    "        if attr == 'step':\n",
    "            return self.step\n",
    "        else:\n",
    "            return getattr(self.env,attr)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:34:46,219] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "GAME_NAME = 'ppaquette/DoomBasic-v0'\n",
    "env = Frameskipper(ToDiscrete(\"minimal\")(gym.make(GAME_NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe559d7f550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAD+CAYAAABY8JzvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe560e71f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs,r,done,_=env.step(1)\n",
    "print r, done\n",
    "plt.imshow(preprocess(obs),cmap='gray',interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import *\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,IMAGE_W,IMAGE_H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import WindowAugmentation,LSTMCell,RNNCell\n",
    "\n",
    "#store 4-tick window in order to perceive motion of objects\n",
    "\n",
    "prev_window = InputLayer((None,4,IMAGE_W,IMAGE_H))\n",
    "\n",
    "current_window = WindowAugmentation(observation_layer,prev_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import Conv2DLayer,Pool2DLayer,DenseLayer,batch_norm,dropout\n",
    "\n",
    "#main neural network body\n",
    "conv0 = Conv2DLayer(current_window,32,filter_size=(8,8),stride=(4,4),name='conv0')\n",
    "\n",
    "conv1 = Conv2DLayer(batch_norm(conv0),64,filter_size=(4,4),stride=(2,2),name='conv1')\n",
    "\n",
    "dense0 = DenseLayer(batch_norm(conv1),512,name='dense',nonlinearity = lasagne.nonlinearities.tanh)\n",
    "\n",
    "#please set this to your last layer for convenience\n",
    "last_layer = dense0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(last_layer,\n",
    "                   num_units = env.action_space.n,\n",
    "                   nonlinearity=lasagne.nonlinearities.linear,\n",
    "                   name=\"q-evaluator layer\")\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer,name=\"e-greedy action picker\")\n",
    "\n",
    "action_layer.epsilon.set_value(np.float32(0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.target_network import TargetNetwork\n",
    "targetnet = TargetNetwork(qvalues_layer,dense0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qvalues_old = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer,qvalues_old),\n",
    "              agent_states={current_window:prev_window},\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[conv0.W,\n",
       " conv0_bn.beta,\n",
       " conv0_bn.gamma,\n",
       " conv1.W,\n",
       " conv1_bn.beta,\n",
       " conv1_bn.gamma,\n",
       " dense.W,\n",
       " dense.b,\n",
       " q-evaluator layer.W,\n",
       " q-evaluator layer.b]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:34:49,377] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,lambda:Frameskipper(ToDiscrete(\"minimal\")(gym.make(GAME_NAME))), \n",
    "               preprocess_observation=preprocess,\n",
    "               n_games=N_AGENTS,max_size=1000) #may need to adjust for speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0 0 0 0]]\n",
      "[[-4. -4. -4. -4. -4. -4.  0.]]\n",
      "CPU times: user 317 ms, sys: 453 ms, total: 769 ms\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_log[:2])\n",
    "print(reward_log[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay#.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(qvalues_seq,old_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#crop rewards to [-1,+1] to avoid explosion.\n",
    "#import theano.tensor as T\n",
    "#rewards = T.maximum(-1,T.minimum(rewards,1))\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      Qvalues_target=old_qvalues_seq,\n",
    "                                                      gamma_or_gammas=0.95,)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:35:00,498] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:35:00,512] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2016-11-28 00:35:00,751] Starting new video recorder writing to /root/drqn/records/openaigym.video.0.18681.video000000.mp4\n",
      "[2016-11-28 00:35:03,428] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-350.0\n"
     ]
    }
   ],
   "source": [
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"records/openaigym.video.94.4407.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_path=\"records/openaigym.video.94.4407.video000000.mp4\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.954\treward/step=-1.50909\n",
      "iter=20\tepsilon=0.910\treward/step=-1.52381\n",
      "iter=30\tepsilon=0.868\treward/step=-2.29032\n",
      "iter=40\tepsilon=0.828\treward/step=-2.58049\n",
      "iter=50\tepsilon=0.790\treward/step=-2.37647\n",
      "iter=60\tepsilon=0.754\treward/step=-2.60984\n",
      "iter=70\tepsilon=0.719\treward/step=-2.44225\n",
      "iter=80\tepsilon=0.687\treward/step=-2.06420\n",
      "iter=90\tepsilon=0.656\treward/step=-2.27692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:35:34,193] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:35:34,200] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.626\treward/step=-2.42574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:35:35,780] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-400.0\n",
      "iter=110\tepsilon=0.598\treward/step=-2.54054\n",
      "iter=120\tepsilon=0.571\treward/step=-2.63471\n",
      "iter=130\tepsilon=0.546\treward/step=-2.69313\n",
      "iter=140\tepsilon=0.522\treward/step=-2.76454\n",
      "iter=150\tepsilon=0.499\treward/step=-2.66225\n",
      "iter=160\tepsilon=0.477\treward/step=-2.58012\n",
      "iter=170\tepsilon=0.456\treward/step=-2.53099\n",
      "iter=180\tepsilon=0.436\treward/step=-2.36243\n",
      "iter=190\tepsilon=0.417\treward/step=-2.33298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:36:46,046] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:36:46,054] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.399\treward/step=-2.39602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:36:47,622] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-380.0\n",
      "iter=210\tepsilon=0.382\treward/step=-2.46730\n",
      "iter=220\tepsilon=0.366\treward/step=-2.50860\n",
      "iter=230\tepsilon=0.351\treward/step=-2.55584\n",
      "iter=240\tepsilon=0.336\treward/step=-2.59834\n",
      "iter=250\tepsilon=0.322\treward/step=-2.64223\n",
      "iter=260\tepsilon=0.309\treward/step=-2.67816\n",
      "iter=270\tepsilon=0.296\treward/step=-2.71587\n",
      "iter=280\tepsilon=0.284\treward/step=-2.74662\n",
      "iter=290\tepsilon=0.273\treward/step=-2.77251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:38:37,277] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:38:37,285] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.262\treward/step=-2.79668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:38:38,771] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-405.0\n",
      "iter=310\tepsilon=0.252\treward/step=-2.60000\n",
      "iter=320\tepsilon=0.242\treward/step=-2.63801\n",
      "iter=330\tepsilon=0.232\treward/step=-2.68520\n",
      "iter=340\tepsilon=0.224\treward/step=-2.58299\n",
      "iter=350\tepsilon=0.215\treward/step=-2.42165\n",
      "iter=360\tepsilon=0.207\treward/step=-2.45152\n",
      "iter=370\tepsilon=0.199\treward/step=-2.48518\n",
      "iter=380\tepsilon=0.192\treward/step=-2.51654\n",
      "iter=390\tepsilon=0.185\treward/step=-2.54680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:41:07,348] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:41:07,355] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.179\treward/step=-2.47332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:41:08,948] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-455.0\n",
      "iter=410\tepsilon=0.172\treward/step=-2.45450\n",
      "iter=420\tepsilon=0.166\treward/step=-2.49121\n",
      "iter=430\tepsilon=0.161\treward/step=-2.47146\n",
      "iter=440\tepsilon=0.155\treward/step=-2.44354\n",
      "iter=450\tepsilon=0.150\treward/step=-2.47140\n",
      "iter=460\tepsilon=0.145\treward/step=-2.49111\n",
      "iter=470\tepsilon=0.141\treward/step=-2.46030\n",
      "iter=480\tepsilon=0.136\treward/step=-2.48191\n",
      "iter=490\tepsilon=0.132\treward/step=-2.37067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:44:18,782] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:44:18,788] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.128\treward/step=-2.35010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:44:19,556] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 37 timesteps with reward=-74.0\n",
      "iter=510\tepsilon=0.124\treward/step=-2.25245\n",
      "iter=520\tepsilon=0.121\treward/step=-2.24568\n",
      "iter=530\tepsilon=0.117\treward/step=-2.27119\n",
      "iter=540\tepsilon=0.114\treward/step=-2.17116\n",
      "iter=550\tepsilon=0.111\treward/step=-2.16624\n",
      "iter=560\tepsilon=0.108\treward/step=-2.15330\n",
      "iter=570\tepsilon=0.105\treward/step=-2.05990\n",
      "iter=580\tepsilon=0.102\treward/step=-2.04578\n",
      "iter=590\tepsilon=0.100\treward/step=-2.03959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:48:08,416] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:48:08,423] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.097\treward/step=-1.95840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:48:09,985] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-360.0\n",
      "iter=610\tepsilon=0.095\treward/step=-1.94828\n",
      "iter=620\tepsilon=0.093\treward/step=-1.97649\n",
      "iter=630\tepsilon=0.091\treward/step=-1.96450\n",
      "iter=640\tepsilon=0.089\treward/step=-1.91950\n",
      "iter=650\tepsilon=0.087\treward/step=-1.93917\n",
      "iter=660\tepsilon=0.085\treward/step=-1.96097\n",
      "iter=670\tepsilon=0.083\treward/step=-1.98241\n",
      "iter=680\tepsilon=0.082\treward/step=-2.00881\n",
      "iter=690\tepsilon=0.080\treward/step=-2.00521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:52:44,409] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:52:44,415] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.079\treward/step=-2.03081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:52:46,227] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-355.0\n",
      "iter=710\tepsilon=0.077\treward/step=-2.01800\n",
      "iter=720\tepsilon=0.076\treward/step=-2.03856\n",
      "iter=730\tepsilon=0.075\treward/step=-2.00137\n",
      "iter=740\tepsilon=0.073\treward/step=-2.02564\n",
      "iter=750\tepsilon=0.072\treward/step=-1.98855\n",
      "iter=760\tepsilon=0.071\treward/step=-1.89698\n",
      "iter=770\tepsilon=0.070\treward/step=-1.91647\n",
      "iter=780\tepsilon=0.069\treward/step=-1.93803\n",
      "iter=790\tepsilon=0.068\treward/step=-1.87560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:58:48,343] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 00:58:48,350] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.067\treward/step=-1.89463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 00:58:48,651] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 2 timesteps with reward=96.0\n",
      "iter=810\tepsilon=0.067\treward/step=-1.88607\n",
      "iter=820\tepsilon=0.066\treward/step=-1.87722\n",
      "iter=830\tepsilon=0.065\treward/step=-1.89434\n",
      "iter=840\tepsilon=0.064\treward/step=-1.89132\n",
      "iter=850\tepsilon=0.064\treward/step=-1.88719\n",
      "iter=860\tepsilon=0.063\treward/step=-1.88432\n",
      "iter=870\tepsilon=0.062\treward/step=-1.90402\n",
      "iter=880\tepsilon=0.062\treward/step=-1.90261\n",
      "iter=890\tepsilon=0.061\treward/step=-1.92166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:05:29,036] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:05:29,043] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.061\treward/step=-1.91387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:05:29,359] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 2 timesteps with reward=96.0\n",
      "iter=910\tepsilon=0.060\treward/step=-1.93238\n",
      "iter=920\tepsilon=0.060\treward/step=-1.94940\n",
      "iter=930\tepsilon=0.059\treward/step=-1.92009\n",
      "iter=940\tepsilon=0.059\treward/step=-1.93900\n",
      "iter=950\tepsilon=0.058\treward/step=-1.95415\n",
      "iter=960\tepsilon=0.058\treward/step=-1.90718\n",
      "iter=970\tepsilon=0.057\treward/step=-1.89928\n",
      "iter=980\tepsilon=0.057\treward/step=-1.91254\n",
      "iter=990\tepsilon=0.057\treward/step=-1.92735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:12:59,755] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:12:59,762] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.056\treward/step=-1.91920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:13:01,604] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-390.0\n",
      "iter=1010\tepsilon=0.056\treward/step=-1.94280\n",
      "iter=1020\tepsilon=0.056\treward/step=-1.95920\n",
      "iter=1030\tepsilon=0.056\treward/step=-1.91540\n",
      "iter=1040\tepsilon=0.055\treward/step=-1.81100\n",
      "iter=1050\tepsilon=0.055\treward/step=-1.83860\n",
      "iter=1060\tepsilon=0.055\treward/step=-1.83960\n",
      "iter=1070\tepsilon=0.055\treward/step=-1.83860\n",
      "iter=1080\tepsilon=0.054\treward/step=-1.88380\n",
      "iter=1090\tepsilon=0.054\treward/step=-1.88480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:21:04,315] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:21:04,321] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.054\treward/step=-1.88580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:21:05,840] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-445.0\n",
      "iter=1110\tepsilon=0.054\treward/step=-1.86760\n",
      "iter=1120\tepsilon=0.054\treward/step=-1.87280\n",
      "iter=1130\tepsilon=0.053\treward/step=-1.87660\n",
      "iter=1140\tepsilon=0.053\treward/step=-1.79000\n",
      "iter=1150\tepsilon=0.053\treward/step=-1.74940\n",
      "iter=1160\tepsilon=0.053\treward/step=-1.77300\n",
      "iter=1170\tepsilon=0.053\treward/step=-1.72480\n",
      "iter=1180\tepsilon=0.053\treward/step=-1.69720\n",
      "iter=1190\tepsilon=0.052\treward/step=-1.64840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:29:04,844] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:29:04,858] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.052\treward/step=-1.64740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:29:05,222] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=88.0\n",
      "iter=1210\tepsilon=0.052\treward/step=-1.61880\n",
      "iter=1220\tepsilon=0.052\treward/step=-1.57380\n",
      "iter=1230\tepsilon=0.052\treward/step=-1.46460\n",
      "iter=1240\tepsilon=0.052\treward/step=-1.37440\n",
      "iter=1250\tepsilon=0.052\treward/step=-1.30660\n",
      "iter=1260\tepsilon=0.052\treward/step=-1.30480\n",
      "iter=1270\tepsilon=0.052\treward/step=-1.27800\n",
      "iter=1280\tepsilon=0.052\treward/step=-1.16760\n",
      "iter=1290\tepsilon=0.052\treward/step=-1.09980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:37:30,494] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:37:30,504] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\tepsilon=0.051\treward/step=-1.07520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:37:30,911] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=72.0\n",
      "iter=1310\tepsilon=0.051\treward/step=-1.14240\n",
      "iter=1320\tepsilon=0.051\treward/step=-1.11440\n",
      "iter=1330\tepsilon=0.051\treward/step=-1.10440\n",
      "iter=1340\tepsilon=0.051\treward/step=-1.12160\n",
      "iter=1350\tepsilon=0.051\treward/step=-1.09800\n",
      "iter=1360\tepsilon=0.051\treward/step=-1.03220\n",
      "iter=1370\tepsilon=0.051\treward/step=-0.98700\n",
      "iter=1380\tepsilon=0.051\treward/step=-0.87520\n",
      "iter=1390\tepsilon=0.051\treward/step=-0.76360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:45:44,378] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:45:44,391] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\tepsilon=0.051\treward/step=-0.67000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:45:44,859] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 9 timesteps with reward=68.0\n",
      "iter=1410\tepsilon=0.051\treward/step=-0.66540\n",
      "iter=1420\tepsilon=0.051\treward/step=-0.63860\n",
      "iter=1430\tepsilon=0.051\treward/step=-0.52540\n",
      "iter=1440\tepsilon=0.051\treward/step=-0.48160\n",
      "iter=1450\tepsilon=0.051\treward/step=-0.46000\n",
      "iter=1460\tepsilon=0.051\treward/step=-0.32940\n",
      "iter=1470\tepsilon=0.051\treward/step=-0.30900\n",
      "iter=1480\tepsilon=0.051\treward/step=-0.24360\n",
      "iter=1490\tepsilon=0.051\treward/step=-0.22100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:53:56,157] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 01:53:56,164] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\tepsilon=0.051\treward/step=-0.19740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 01:53:56,699] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 11 timesteps with reward=52.0\n",
      "iter=1510\tepsilon=0.050\treward/step=-0.19100\n",
      "iter=1520\tepsilon=0.050\treward/step=-0.14420\n",
      "iter=1530\tepsilon=0.050\treward/step=-0.10000\n",
      "iter=1540\tepsilon=0.050\treward/step=-0.09960\n",
      "iter=1550\tepsilon=0.050\treward/step=-0.04780\n",
      "iter=1560\tepsilon=0.050\treward/step=-0.00680\n",
      "iter=1570\tepsilon=0.050\treward/step=-0.02760\n",
      "iter=1580\tepsilon=0.050\treward/step=0.01300\n",
      "iter=1590\tepsilon=0.050\treward/step=0.01940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:01:48,567] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:01:48,575] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1600\tepsilon=0.050\treward/step=0.02180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:01:50,092] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 88 timesteps with reward=-425.0\n",
      "iter=1610\tepsilon=0.050\treward/step=0.08420\n",
      "iter=1620\tepsilon=0.050\treward/step=0.21880\n",
      "iter=1630\tepsilon=0.050\treward/step=0.34860\n",
      "iter=1640\tepsilon=0.050\treward/step=0.39220\n",
      "iter=1650\tepsilon=0.050\treward/step=0.52180\n",
      "iter=1660\tepsilon=0.050\treward/step=0.60840\n",
      "iter=1670\tepsilon=0.050\treward/step=0.71740\n",
      "iter=1680\tepsilon=0.050\treward/step=0.82660\n",
      "iter=1690\tepsilon=0.050\treward/step=0.89760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:08:39,655] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:08:39,662] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1700\tepsilon=0.050\treward/step=0.96640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:08:40,023] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=72.0\n",
      "iter=1710\tepsilon=0.050\treward/step=1.02960\n",
      "iter=1720\tepsilon=0.050\treward/step=1.16220\n",
      "iter=1730\tepsilon=0.050\treward/step=1.25160\n",
      "iter=1740\tepsilon=0.050\treward/step=1.36560\n",
      "iter=1750\tepsilon=0.050\treward/step=1.43240\n",
      "iter=1760\tepsilon=0.050\treward/step=1.43600\n",
      "iter=1770\tepsilon=0.050\treward/step=1.58920\n",
      "iter=1780\tepsilon=0.050\treward/step=1.67960\n",
      "iter=1790\tepsilon=0.050\treward/step=1.70300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:15:28,151] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:15:28,158] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1800\tepsilon=0.050\treward/step=1.79040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:15:28,572] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 11 timesteps with reward=55.0\n",
      "iter=1810\tepsilon=0.050\treward/step=1.87740\n",
      "iter=1820\tepsilon=0.050\treward/step=1.96400\n",
      "iter=1830\tepsilon=0.050\treward/step=2.07140\n",
      "iter=1840\tepsilon=0.050\treward/step=2.16380\n",
      "iter=1850\tepsilon=0.050\treward/step=2.23140\n",
      "iter=1860\tepsilon=0.050\treward/step=2.30060\n",
      "iter=1870\tepsilon=0.050\treward/step=2.38940\n",
      "iter=1880\tepsilon=0.050\treward/step=2.37120\n",
      "iter=1890\tepsilon=0.050\treward/step=2.46060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:22:17,122] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:22:17,129] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1900\tepsilon=0.050\treward/step=2.54740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:22:17,435] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=88.0\n",
      "iter=1910\tepsilon=0.050\treward/step=2.57000\n",
      "iter=1920\tepsilon=0.050\treward/step=2.63300\n",
      "iter=1930\tepsilon=0.050\treward/step=2.70200\n",
      "iter=1940\tepsilon=0.050\treward/step=2.74820\n",
      "iter=1950\tepsilon=0.050\treward/step=2.83640\n",
      "iter=1960\tepsilon=0.050\treward/step=2.82100\n",
      "iter=1970\tepsilon=0.050\treward/step=2.81900\n",
      "iter=1980\tepsilon=0.050\treward/step=2.92400\n",
      "iter=1990\tepsilon=0.050\treward/step=2.96700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:29:05,160] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:29:05,167] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2000\tepsilon=0.050\treward/step=3.03280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:29:05,538] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=72.0\n",
      "iter=2010\tepsilon=0.050\treward/step=3.07500\n",
      "iter=2020\tepsilon=0.050\treward/step=3.11380\n",
      "iter=2030\tepsilon=0.050\treward/step=3.07600\n",
      "iter=2040\tepsilon=0.050\treward/step=2.99300\n",
      "iter=2050\tepsilon=0.050\treward/step=2.99800\n",
      "iter=2060\tepsilon=0.050\treward/step=3.00520\n",
      "iter=2070\tepsilon=0.050\treward/step=3.02260\n",
      "iter=2080\tepsilon=0.050\treward/step=3.15680\n",
      "iter=2090\tepsilon=0.050\treward/step=3.24820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:36:24,056] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:36:24,064] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2100\tepsilon=0.050\treward/step=3.36080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:36:24,508] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 10 timesteps with reward=64.0\n",
      "iter=2110\tepsilon=0.050\treward/step=3.43380\n",
      "iter=2120\tepsilon=0.050\treward/step=3.52820\n",
      "iter=2130\tepsilon=0.050\treward/step=3.61660\n",
      "iter=2140\tepsilon=0.050\treward/step=3.66460\n",
      "iter=2150\tepsilon=0.050\treward/step=3.68720\n",
      "iter=2160\tepsilon=0.050\treward/step=3.73540\n",
      "iter=2170\tepsilon=0.050\treward/step=3.73540\n",
      "iter=2180\tepsilon=0.050\treward/step=3.79800\n",
      "iter=2190\tepsilon=0.050\treward/step=3.86320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:44:14,261] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:44:14,267] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2200\tepsilon=0.050\treward/step=4.01380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:44:14,582] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 2 timesteps with reward=96.0\n",
      "iter=2210\tepsilon=0.050\treward/step=4.07480\n",
      "iter=2220\tepsilon=0.050\treward/step=4.04560\n",
      "iter=2230\tepsilon=0.050\treward/step=4.02400\n",
      "iter=2240\tepsilon=0.050\treward/step=4.06380\n",
      "iter=2250\tepsilon=0.050\treward/step=4.15220\n",
      "iter=2260\tepsilon=0.050\treward/step=4.26120\n",
      "iter=2270\tepsilon=0.050\treward/step=4.36600\n",
      "iter=2280\tepsilon=0.050\treward/step=4.34340\n",
      "iter=2290\tepsilon=0.050\treward/step=4.36300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:52:49,363] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 02:52:49,370] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2300\tepsilon=0.050\treward/step=4.35600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:52:49,685] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 2 timesteps with reward=96.0\n",
      "iter=2310\tepsilon=0.050\treward/step=4.35200\n",
      "iter=2320\tepsilon=0.050\treward/step=4.39620\n",
      "iter=2330\tepsilon=0.050\treward/step=4.48060\n",
      "iter=2340\tepsilon=0.050\treward/step=4.56340\n",
      "iter=2350\tepsilon=0.050\treward/step=4.58500\n",
      "iter=2360\tepsilon=0.050\treward/step=4.67180\n",
      "iter=2370\tepsilon=0.050\treward/step=4.71500\n",
      "iter=2380\tepsilon=0.050\treward/step=4.71500\n",
      "iter=2390\tepsilon=0.050\treward/step=4.73420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:01:54,814] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 03:01:54,820] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2400\tepsilon=0.050\treward/step=4.73260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:01:55,244] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=72.0\n",
      "iter=2410\tepsilon=0.050\treward/step=4.83980\n",
      "iter=2420\tepsilon=0.050\treward/step=4.92660\n",
      "iter=2430\tepsilon=0.050\treward/step=4.90440\n",
      "iter=2440\tepsilon=0.050\treward/step=4.89880\n",
      "iter=2450\tepsilon=0.050\treward/step=4.98840\n",
      "iter=2460\tepsilon=0.050\treward/step=4.94680\n",
      "iter=2470\tepsilon=0.050\treward/step=5.01180\n",
      "iter=2480\tepsilon=0.050\treward/step=5.01060\n",
      "iter=2490\tepsilon=0.050\treward/step=5.02680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:10:06,928] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 03:10:06,935] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2500\tepsilon=0.050\treward/step=5.06880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:10:07,344] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=65.0\n",
      "iter=2510\tepsilon=0.050\treward/step=5.10920\n",
      "iter=2520\tepsilon=0.050\treward/step=5.11060\n",
      "iter=2530\tepsilon=0.050\treward/step=5.06940\n",
      "iter=2540\tepsilon=0.050\treward/step=5.05000\n",
      "iter=2550\tepsilon=0.050\treward/step=5.09000\n",
      "iter=2560\tepsilon=0.050\treward/step=5.15960\n",
      "iter=2570\tepsilon=0.050\treward/step=5.22460\n",
      "iter=2580\tepsilon=0.050\treward/step=5.33640\n",
      "iter=2590\tepsilon=0.050\treward/step=5.40200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:18:01,370] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 03:18:01,377] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2600\tepsilon=0.050\treward/step=5.42460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:18:01,722] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=88.0\n",
      "iter=2610\tepsilon=0.050\treward/step=5.47040\n",
      "iter=2620\tepsilon=0.050\treward/step=5.42460\n",
      "iter=2630\tepsilon=0.050\treward/step=5.38300\n",
      "iter=2640\tepsilon=0.050\treward/step=5.40460\n",
      "iter=2650\tepsilon=0.050\treward/step=5.38300\n",
      "iter=2660\tepsilon=0.050\treward/step=5.40620\n",
      "iter=2670\tepsilon=0.050\treward/step=5.38100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-32867afc21b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#you may want to increase the number of training iterations per one update\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtargetnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in xrange(10**7):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    for i in range(1): #you may want to increase the number of training iterations per one update\n",
    "        loss = train_step()\n",
    "    targetnet.load_weights(0.01)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.95*np.exp(-epoch_counter/200.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%100 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "#         plt.title(\"random frames\")\n",
    "#         for i in range(min((len(pool.games),6))):\n",
    "#             plt.subplot(2,3,i+1)\n",
    "#             plt.imshow(pool.games[i].get_observation())\n",
    "#         plt.show()\n",
    "\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#^--- coffee cup got empty, got bored >.<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe53d7d3250>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe515b59e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*sorted(list(rewards.items()),key=lambda p:p[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:24:34,901] Making new env: ppaquette/DoomBasic-v0\n",
      "[2016-11-28 03:24:34,909] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 12 timesteps with reward=46.0\n",
      "Episode finished after 20 timesteps with reward=3.0\n",
      "Episode finished after 8 timesteps with reward=65.0\n",
      "Episode finished after 5 timesteps with reward=84.0\n",
      "Episode finished after 12 timesteps with reward=48.0\n",
      "Episode finished after 10 timesteps with reward=59.0\n",
      "Episode finished after 3 timesteps with reward=92.0\n",
      "Episode finished after 5 timesteps with reward=84.0\n",
      "Episode finished after 2 timesteps with reward=96.0\n",
      "Episode finished after 8 timesteps with reward=65.0\n",
      "Episode finished after 7 timesteps with reward=76.0\n",
      "Episode finished after 5 timesteps with reward=84.0\n",
      "Episode finished after 2 timesteps with reward=96.0\n",
      "Episode finished after 13 timesteps with reward=40.0\n",
      "Episode finished after 8 timesteps with reward=72.0\n",
      "Episode finished after 4 timesteps with reward=88.0\n",
      "Episode finished after 2 timesteps with reward=96.0\n",
      "Episode finished after 8 timesteps with reward=65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:24:38,575] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=88.0\n",
      "Episode finished after 2 timesteps with reward=96.0\n",
      "mean session score=72.150000.5\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20,save_path=\"./records\",record_video=True)\n",
    "print(\"mean session score=%f.5\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "#save for display\n",
    "save(action_layer,\"doombasic_dqn_2500.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "#select the one you want\n",
    "video_path=\"<writeme>\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Once you got it working,\n",
    "Try building a network that maximizes the final score\n",
    "\n",
    "* Moar lasagne stuff: convolutional layers, batch normalization, nonlinearities and so on\n",
    "* Recurrent agent memory layers, GRUMemoryLayer, etc\n",
    "* Different reinforcement learning algorithm (p.e. qlearning_n_step), other parameters\n",
    "* Experience replay pool\n",
    "\n",
    "\n",
    "Look for info?\n",
    "* [lasagne doc](http://lasagne.readthedocs.io/en/latest/)\n",
    "* [agentnet doc](http://agentnet.readthedocs.io/en/latest/)\n",
    "* [gym homepage](http://gym.openai.com/)\n",
    "\n",
    "\n",
    "You can also try to expand to a different game: \n",
    " * all OpenAI Atari games are already compatible, you only need to change GAME_TITLE\n",
    " * Other discrete action space environments are also accessible this way\n",
    " * For continuous action spaces, either discretize actions or use continuous RL algorithms (e.g. .learning.dpg_n_step)\n",
    " * Adapting to a custom non-OpenAI environment can be done with a simple wrapper\n",
    " \n",
    " \n",
    "__Good luck!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
