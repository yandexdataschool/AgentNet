{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatami\n",
    "\n",
    "I am a simple experiment on using VIME with actor-critic agent setup for MountainCar problem.\n",
    "\n",
    "Original experiment: https://github.com/justheuristic/vime\n",
    "\n",
    "Vime performance varies greatly depending on BNN.curiosity parameter so pls pay attention to it :)\n",
    "* Large curiosity makes agent quickly learn to do weird things, some of which improve it's policy\n",
    "* Low curiosity is close to vanilla a2c\n",
    "\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"floatX=float32\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS=\"floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "GAME = \"MountainCar-v0\"\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:19:44,511] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40586736 -0.00187794]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "env = gym.make(GAME)\n",
    "obs = env.step(0)[0]\n",
    "action_names = np.array([\"left\",'stop',\"right\"]) #i guess so... i may be wrong\n",
    "state_size = len(obs)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using shallow neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer,DenseLayer,NonlinearityLayer,batch_norm,dropout\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,state_size))\n",
    "\n",
    "dense0 = DenseLayer(observation_layer,100,name='dense1')\n",
    "dense1 = DenseLayer(dense0,256,name='dense2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "\n",
    "policy_layer = DenseLayer(dense1,\n",
    "                   num_units = env.action_space.n,\n",
    "                   nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                   name=\"q-evaluator layer\")\n",
    "\n",
    "\n",
    "V_layer = DenseLayer(dense1, 1, nonlinearity=None,name=\"state values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import theano\n",
    "epsilon = theano.shared(np.float32(0),allow_downcast=True)\n",
    "policy_smooth_layer = NonlinearityLayer(policy_layer,\n",
    "                                        lambda p: (1.-epsilon)*p + epsilon/env.action_space.n)\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import ProbabilisticResolver\n",
    "action_layer = ProbabilisticResolver(policy_smooth_layer,\n",
    "                                     name=\"e-greedy action picker\",\n",
    "                                     assume_normalized=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(policy_layer,V_layer),\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dense1.W,\n",
       " dense1.b,\n",
       " dense2.W,\n",
       " dense2.b,\n",
       " q-evaluator layer.W,\n",
       " q-evaluator layer.b,\n",
       " state values.W,\n",
       " state values.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params((action_layer,V_layer),trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:19:45,651] Making new env: MountainCar-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,GAME, N_AGENTS,max_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['right' 'left' 'left' 'right' 'left' 'left' 'left']]\n",
      "[[-1. -1. -1. -1. -1. -1.  0.]]\n",
      "CPU times: user 4.85 ms, sys: 252 µs, total: 5.1 ms\n",
      "Wall time: 4.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_names[action_log])\n",
    "print(reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a2c loss\n",
    "\n",
    "Here we define obective function for actor-critic (one-step) RL.\n",
    "\n",
    "* We regularize policy with expected inverse action probabilities (discouraging very small probas) to make objective numerically stable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(policy_seq,V_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    optimize_experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import a2c_n_step\n",
    "\n",
    "#loss for actor-critic\n",
    "\n",
    "elwise_mse_loss = a2c_n_step.get_elementwise_objective(policy_seq,V_seq[:,:,0],\n",
    "                                                       replay.actions[0],\n",
    "                                                       replay.rewards,\n",
    "                                                       replay.is_alive,\n",
    "                                                       gamma_or_gammas=0.99,\n",
    "                                                       n_steps=1)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "reg_entropy = T.mean((1./policy_seq))\n",
    "loss += 0.01*reg_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.rmsprop(loss,weights,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:19:55,894] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:19:55,897] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2016-11-28 03:19:55,940] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=-200.0\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_path=\"<insert path from previous cell starting from records>\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bnn import bbpwrap, NormalApproximation,sample_output\n",
    "from lasagne.layers import EmbeddingLayer\n",
    "import theano.tensor as T\n",
    "@bbpwrap(NormalApproximation())\n",
    "class BayesDenseLayer(DenseLayer):pass\n",
    "@bbpwrap(NormalApproximation())\n",
    "class BayesEmbLayer(EmbeddingLayer):pass\n",
    "\n",
    "from curiosity import compile_vime_reward\n",
    "\n",
    "class BNN:\n",
    "    curiosity=0.01\n",
    "    target_rho = 1\n",
    "    \n",
    "    l_state = InputLayer((None,state_size),name='state var')\n",
    "    l_action = InputLayer((None,),input_var=T.ivector())\n",
    "\n",
    "    l_action_emb = BayesEmbLayer(l_action,env.action_space.n, 3)    \n",
    "    \n",
    "    l_concat = lasagne.layers.concat([l_action_emb,l_state])\n",
    "    \n",
    "    l_dense = BayesDenseLayer(l_concat,num_units=50,\n",
    "                              nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    l_out = BayesDenseLayer(l_dense,num_units=state_size,\n",
    "                            nonlinearity=None)\n",
    "        \n",
    "    params = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "    ###training###\n",
    "    pred_states = lasagne.layers.get_output(l_out)\n",
    "    next_states = T.matrix(\"next states\")\n",
    "    mse = lasagne.objectives.squared_error(pred_states,next_states).mean()\n",
    "    \n",
    "    #replace logposterior with simple regularization on rho cuz we're lazy\n",
    "    reg = sum([lasagne.objectives.squared_error(rho,target_rho).mean() \n",
    "              for rho in lasagne.layers.get_all_params(l_out,rho=True)])\n",
    "    \n",
    "    loss = mse+ 0.01*reg\n",
    "    \n",
    "    updates = lasagne.updates.adam(loss,params)\n",
    "    \n",
    "    train_step = theano.function([l_state.input_var,l_action.input_var,next_states],\n",
    "                                 loss,updates=updates)\n",
    "    \n",
    "    ###sample random sessions from pool###\n",
    "    observations, = replay.observations\n",
    "    actions, = replay.actions\n",
    "    observations_flat = observations[:,:-1].reshape((-1,)+tuple(observations.shape[2:]))\n",
    "    actions_flat = actions[:,:-1].reshape((-1,))\n",
    "    next_observations_flat = observations[:,1:].reshape((-1,)+tuple(observations.shape[2:]))\n",
    "    sample_from_pool = theano.function([],[observations_flat,actions_flat,next_observations_flat])\n",
    "\n",
    "    \n",
    "    ###curiosity reward### aka KL(qnew,qold)\n",
    "    get_vime_reward_elwise = compile_vime_reward(l_out,l_state,l_action,params,n_samples=10)\n",
    "    \n",
    "    ###moving average of KL used to normalize over it\n",
    "    vime_reward_ma = 10.\n",
    "    ma_alpha=0.01\n",
    "\n",
    "    @staticmethod\n",
    "    def add_vime_reward(observations,actions,rewards,is_alive,h0):\n",
    "        assert isinstance(observations,np.ndarray)\n",
    "        observations_flat = observations[:,:-1].reshape((-1,)+observations.shape[2:]).astype('float32')\n",
    "        actions_flat = actions[:,:-1].reshape((-1,)).astype('int32')\n",
    "        next_observations_flat = observations[:,1:].reshape((-1,)+observations.shape[2:]).astype('float32')\n",
    "\n",
    "        vime_rewards = BNN.get_vime_reward_elwise(observations_flat,actions_flat,next_observations_flat)\n",
    "        vime_rewards = np.concatenate([vime_rewards.reshape(rewards[:,:-1].shape),\n",
    "                                       np.zeros_like(rewards[:,-1:]),], axis=1)\n",
    "        #normalize by moving average\n",
    "        BNN.vime_reward_ma = (1.-BNN.ma_alpha)*BNN.vime_reward_ma + BNN.ma_alpha*vime_rewards.mean()\n",
    "        \n",
    "        surrogate_rewards = rewards + BNN.curiosity/BNN.vime_reward_ma*vime_rewards\n",
    "        return (observations,actions,surrogate_rewards,is_alive,h0)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 162.01it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 372.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#pre-fill pool\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1000)):\n",
    "    pool.update(SEQ_LENGTH,append=True,preprocess=BNN.add_vime_reward)\n",
    "\n",
    "#pre-train BNN (mitigate training lag on first iterations where BNN is stupid)\n",
    "for i in tqdm(range(1000)):\n",
    "    BNN.train_step(*BNN.sample_from_pool())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/10000 [00:19<32:50,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.000\treward/step=-0.98942\tpool_size=2001\tvime ma=3.89503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 201/10000 [00:39<30:03,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.000\treward/step=-0.98942\tpool_size=3001\tvime ma=2.31922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 301/10000 [00:58<33:24,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.000\treward/step=-0.98939\tpool_size=4001\tvime ma=1.57553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 401/10000 [01:17<30:18,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.000\treward/step=-0.98938\tpool_size=5001\tvime ma=0.94941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 499/10000 [01:36<32:33,  4.86it/s][2016-11-28 03:21:48,990] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:21:48,994] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.000\treward/step=-0.98933\tpool_size=6001\tvime ma=0.64745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:21:49,421] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      "  5%|▌         | 500/10000 [01:36<55:58,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 600/10000 [01:57<33:23,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.050\treward/step=-0.98927\tpool_size=7001\tvime ma=0.43053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 701/10000 [02:18<34:11,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.050\treward/step=-0.98911\tpool_size=8001\tvime ma=0.30550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 801/10000 [02:38<28:17,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.050\treward/step=-0.98883\tpool_size=9001\tvime ma=0.24422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 901/10000 [02:59<29:34,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.050\treward/step=-0.98862\tpool_size=10000\tvime ma=0.15951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [03:19<27:36,  5.43it/s][2016-11-28 03:23:31,959] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:23:31,961] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.050\treward/step=-0.98831\tpool_size=10000\tvime ma=0.11891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:23:32,285] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 10%|█         | 1001/10000 [03:19<37:50,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -161.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1101/10000 [03:39<26:54,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.050\treward/step=-0.98799\tpool_size=10000\tvime ma=0.08223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1201/10000 [03:56<26:26,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.050\treward/step=-0.98764\tpool_size=10000\tvime ma=0.05873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1301/10000 [04:15<28:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\tepsilon=0.050\treward/step=-0.98730\tpool_size=10000\tvime ma=0.04550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1401/10000 [04:33<26:01,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\tepsilon=0.050\treward/step=-0.98696\tpool_size=10000\tvime ma=0.03317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1499/10000 [04:51<25:58,  5.46it/s][2016-11-28 03:25:04,061] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:25:04,064] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\tepsilon=0.050\treward/step=-0.98664\tpool_size=10000\tvime ma=0.02510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:25:04,373] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 15%|█▌        | 1501/10000 [04:52<35:01,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -155.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1601/10000 [05:10<25:24,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1600\tepsilon=0.050\treward/step=-0.98635\tpool_size=10000\tvime ma=0.01965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1701/10000 [05:28<24:52,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1700\tepsilon=0.050\treward/step=-0.98614\tpool_size=10000\tvime ma=0.01633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1801/10000 [05:46<24:34,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1800\tepsilon=0.050\treward/step=-0.98607\tpool_size=10000\tvime ma=0.01429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1901/10000 [06:04<24:05,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1900\tepsilon=0.050\treward/step=-0.98602\tpool_size=10000\tvime ma=0.01104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [06:22<24:07,  5.53it/s][2016-11-28 03:26:34,906] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:26:34,909] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2000\tepsilon=0.050\treward/step=-0.98599\tpool_size=10000\tvime ma=0.01110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:26:35,249] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 20%|██        | 2001/10000 [06:22<33:40,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -165.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2101/10000 [06:41<24:01,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2100\tepsilon=0.050\treward/step=-0.98595\tpool_size=10000\tvime ma=0.01088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2201/10000 [06:59<24:19,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2200\tepsilon=0.050\treward/step=-0.98593\tpool_size=10000\tvime ma=0.01056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2301/10000 [07:18<23:56,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2300\tepsilon=0.050\treward/step=-0.98591\tpool_size=10000\tvime ma=0.01012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2401/10000 [07:36<22:50,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2400\tepsilon=0.050\treward/step=-0.98588\tpool_size=10000\tvime ma=0.01065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [07:54<22:51,  5.47it/s][2016-11-28 03:28:07,001] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:28:07,004] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2500\tepsilon=0.050\treward/step=-0.98584\tpool_size=10000\tvime ma=0.01196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:28:07,298] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 25%|██▌       | 2501/10000 [07:55<30:34,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -140.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2601/10000 [08:13<22:22,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2600\tepsilon=0.050\treward/step=-0.98579\tpool_size=10000\tvime ma=0.01281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2701/10000 [08:31<22:25,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2700\tepsilon=0.050\treward/step=-0.98577\tpool_size=10000\tvime ma=0.01276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2801/10000 [08:49<21:34,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2800\tepsilon=0.050\treward/step=-0.98572\tpool_size=10000\tvime ma=0.01384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2901/10000 [09:08<21:29,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2900\tepsilon=0.050\treward/step=-0.98566\tpool_size=10000\tvime ma=0.01516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [09:26<21:05,  5.53it/s][2016-11-28 03:29:38,655] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:29:38,658] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3000\tepsilon=0.050\treward/step=-0.98561\tpool_size=10000\tvime ma=0.01735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:29:38,916] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 30%|███       | 3001/10000 [09:26<27:35,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -135.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3101/10000 [09:44<20:42,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3100\tepsilon=0.050\treward/step=-0.98556\tpool_size=10000\tvime ma=0.01806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3201/10000 [10:03<21:06,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3200\tepsilon=0.050\treward/step=-0.98553\tpool_size=10000\tvime ma=0.01898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3301/10000 [10:22<20:40,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3300\tepsilon=0.050\treward/step=-0.98552\tpool_size=10000\tvime ma=0.01951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3401/10000 [10:40<20:02,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3400\tepsilon=0.050\treward/step=-0.98550\tpool_size=10000\tvime ma=0.02220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3499/10000 [10:58<20:00,  5.42it/s][2016-11-28 03:31:10,856] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:31:10,859] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3500\tepsilon=0.050\treward/step=-0.98548\tpool_size=10000\tvime ma=0.02412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:31:11,096] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 35%|███▌      | 3501/10000 [10:58<25:25,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -117.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3601/10000 [11:17<19:24,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3600\tepsilon=0.050\treward/step=-0.98548\tpool_size=10000\tvime ma=0.02527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3701/10000 [11:35<19:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3700\tepsilon=0.050\treward/step=-0.98545\tpool_size=10000\tvime ma=0.02624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3801/10000 [11:53<19:49,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3800\tepsilon=0.050\treward/step=-0.98547\tpool_size=10000\tvime ma=0.02705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3901/10000 [12:12<19:40,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3900\tepsilon=0.050\treward/step=-0.98545\tpool_size=10000\tvime ma=0.02814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [12:31<18:34,  5.38it/s][2016-11-28 03:32:43,931] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:32:43,934] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4000\tepsilon=0.050\treward/step=-0.98544\tpool_size=10000\tvime ma=0.03055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:32:44,166] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 40%|████      | 4001/10000 [12:31<23:30,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -116.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4101/10000 [12:50<18:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4100\tepsilon=0.050\treward/step=-0.98542\tpool_size=10000\tvime ma=0.03256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4201/10000 [13:09<18:12,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4200\tepsilon=0.050\treward/step=-0.98539\tpool_size=10000\tvime ma=0.03505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4301/10000 [13:28<17:43,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4300\tepsilon=0.050\treward/step=-0.98537\tpool_size=10000\tvime ma=0.03684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4401/10000 [13:46<17:15,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4400\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.03807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [14:05<16:48,  5.45it/s][2016-11-28 03:34:17,768] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:34:17,770] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4500\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.04080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:34:18,022] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 45%|████▌     | 4501/10000 [14:05<21:59,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -125.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4601/10000 [14:24<16:30,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4600\tepsilon=0.050\treward/step=-0.98532\tpool_size=10000\tvime ma=0.04150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4701/10000 [14:42<16:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4700\tepsilon=0.050\treward/step=-0.98529\tpool_size=10000\tvime ma=0.04679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4801/10000 [15:01<16:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4800\tepsilon=0.050\treward/step=-0.98528\tpool_size=10000\tvime ma=0.04622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4901/10000 [15:19<16:28,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4900\tepsilon=0.050\treward/step=-0.98527\tpool_size=10000\tvime ma=0.04942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [15:37<15:16,  5.46it/s][2016-11-28 03:35:50,518] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:35:50,521] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5000\tepsilon=0.050\treward/step=-0.98527\tpool_size=10000\tvime ma=0.04996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:35:50,768] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 50%|█████     | 5001/10000 [15:38<19:29,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -124.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5101/10000 [15:57<15:06,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5100\tepsilon=0.050\treward/step=-0.98528\tpool_size=10000\tvime ma=0.05426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5201/10000 [16:15<14:29,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5200\tepsilon=0.050\treward/step=-0.98528\tpool_size=10000\tvime ma=0.05492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5301/10000 [16:33<14:29,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5300\tepsilon=0.050\treward/step=-0.98529\tpool_size=10000\tvime ma=0.05637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5401/10000 [16:52<14:06,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5400\tepsilon=0.050\treward/step=-0.98529\tpool_size=10000\tvime ma=0.05847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5499/10000 [17:10<14:04,  5.33it/s][2016-11-28 03:37:23,393] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:37:23,396] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5500\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.06046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:37:23,676] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 55%|█████▌    | 5501/10000 [17:11<18:26,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -123.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5601/10000 [17:29<13:36,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5600\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.06349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5701/10000 [17:48<13:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5700\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.06411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5801/10000 [18:07<12:52,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5800\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.06168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5901/10000 [18:25<12:30,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5900\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.06867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [18:43<12:23,  5.38it/s][2016-11-28 03:38:56,566] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:38:56,569] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6000\tepsilon=0.050\treward/step=-0.98533\tpool_size=10000\tvime ma=0.06793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:38:56,797] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 60%|██████    | 6001/10000 [18:44<15:31,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -115.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6101/10000 [19:03<12:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6100\tepsilon=0.050\treward/step=-0.98533\tpool_size=10000\tvime ma=0.06868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6200/10000 [19:21<11:58,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6200\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.07324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6301/10000 [19:40<11:13,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6300\tepsilon=0.050\treward/step=-0.98532\tpool_size=10000\tvime ma=0.07646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6401/10000 [19:59<11:06,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6400\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.07537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6499/10000 [20:17<10:55,  5.34it/s][2016-11-28 03:40:30,246] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:40:30,250] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6500\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.07968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:40:30,483] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 65%|██████▌   | 6501/10000 [20:18<13:40,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -118.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6601/10000 [20:36<10:34,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6600\tepsilon=0.050\treward/step=-0.98532\tpool_size=10000\tvime ma=0.07800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6701/10000 [20:55<10:19,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6700\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.08015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6801/10000 [21:14<09:53,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6800\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.08592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6901/10000 [21:33<09:41,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6900\tepsilon=0.050\treward/step=-0.98533\tpool_size=10000\tvime ma=0.08751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6999/10000 [21:52<09:21,  5.34it/s][2016-11-28 03:42:05,032] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:42:05,035] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7000\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.08666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:42:05,264] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 70%|███████   | 7001/10000 [21:52<11:45,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -115.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7100/10000 [22:11<08:54,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7100\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.08960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7201/10000 [22:30<08:32,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7200\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.09546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7301/10000 [22:48<08:11,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7300\tepsilon=0.050\treward/step=-0.98537\tpool_size=10000\tvime ma=0.09207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7401/10000 [23:07<08:10,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7400\tepsilon=0.050\treward/step=-0.98537\tpool_size=10000\tvime ma=0.09166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 7499/10000 [23:25<07:46,  5.36it/s][2016-11-28 03:43:38,599] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:43:38,603] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7500\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.09724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:43:38,838] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 75%|███████▌  | 7501/10000 [23:26<09:45,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -122.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7601/10000 [23:45<07:28,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7600\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.09940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7701/10000 [24:03<07:07,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7700\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.10291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7800/10000 [24:22<07:06,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7800\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.10330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7901/10000 [24:41<06:25,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7900\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.10223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7999/10000 [24:59<06:15,  5.33it/s][2016-11-28 03:45:12,042] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:45:12,045] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8000\tepsilon=0.050\treward/step=-0.98533\tpool_size=10000\tvime ma=0.10439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:45:12,303] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 80%|████████  | 8001/10000 [25:00<08:06,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -128.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8101/10000 [25:18<05:50,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8100\tepsilon=0.050\treward/step=-0.98531\tpool_size=10000\tvime ma=0.10884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8201/10000 [25:37<05:34,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8200\tepsilon=0.050\treward/step=-0.98532\tpool_size=10000\tvime ma=0.10987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8301/10000 [25:56<05:24,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8300\tepsilon=0.050\treward/step=-0.98532\tpool_size=10000\tvime ma=0.10977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8401/10000 [26:14<04:53,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8400\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.10989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8499/10000 [26:33<04:47,  5.23it/s][2016-11-28 03:46:45,975] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:46:45,978] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8500\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.11233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:46:46,248] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 85%|████████▌ | 8501/10000 [26:33<06:07,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -131.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8601/10000 [26:52<04:19,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8600\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.11252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8701/10000 [27:11<04:05,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8700\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.11566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8801/10000 [27:30<03:41,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8800\tepsilon=0.050\treward/step=-0.98534\tpool_size=10000\tvime ma=0.12122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8901/10000 [27:49<03:28,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8900\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.12177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8999/10000 [28:07<03:06,  5.38it/s][2016-11-28 03:48:20,072] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:48:20,075] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9000\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.11984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:48:20,310] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 90%|█████████ | 9001/10000 [28:08<03:56,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -117.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9101/10000 [28:26<02:45,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9100\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.12307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9201/10000 [28:45<02:27,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9200\tepsilon=0.050\treward/step=-0.98537\tpool_size=10000\tvime ma=0.11798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9301/10000 [29:03<02:09,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9300\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.12063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9401/10000 [29:22<01:53,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9400\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.12402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9499/10000 [29:41<01:32,  5.39it/s][2016-11-28 03:49:53,743] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:49:53,746] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9500\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.12238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:49:53,973] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 95%|█████████▌| 9501/10000 [29:41<01:57,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -119.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9601/10000 [30:00<01:24,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9600\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.12275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9701/10000 [30:19<00:55,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9700\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.12501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9801/10000 [30:38<00:38,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9800\tepsilon=0.050\treward/step=-0.98536\tpool_size=10000\tvime ma=0.12445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9901/10000 [30:57<00:18,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9900\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.13073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9999/10000 [31:15<00:00,  5.54it/s][2016-11-28 03:51:28,199] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:51:28,202] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10000\tepsilon=0.050\treward/step=-0.98535\tpool_size=10000\tvime ma=0.13354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:51:28,450] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      "100%|██████████| 10000/10000 [31:15<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -125.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "loss = 0\n",
    "for i in tqdm(range(10000)):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    for i in range(10):\n",
    "        pool.update(SEQ_LENGTH,append=True,preprocess=BNN.add_vime_reward)\n",
    "\n",
    "    for i in range(10):\n",
    "        loss = loss*0.99 + train_step()*0.01\n",
    "    \n",
    "    for i in range(10):\n",
    "        BNN.train_step(*BNN.sample_from_pool())\n",
    "\n",
    "    \n",
    "    if epoch_counter%100==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = np.average(pool.experience_replay.rewards.get_value()[:,:-1],\n",
    "                                      weights=1+pool.experience_replay.is_alive.get_value()[:,:-1])\n",
    "        pool_size = pool.experience_replay.rewards.get_value().shape[0]\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\\tpool_size=%i\\tvime ma=%.5f\"%(epoch_counter,\n",
    "                                                         epsilon.get_value(),\n",
    "                                                         pool_mean_reward,\n",
    "                                                         pool_size,\n",
    "                                                         BNN.vime_reward_ma))\n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%500 ==0:\n",
    "        n_games = 10\n",
    "        epsilon.set_value(0)\n",
    "        rewards[epoch_counter] = pool.evaluate( record_video=False,n_games=n_games,verbose=False)\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(n_games,np.mean(rewards[epoch_counter])))\n",
    "        epsilon.set_value(0.05)\n",
    "    \n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda (k,v):k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f72b9314110>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEW+f+6Vhn8tkCj7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72b99cecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('session reward')\n",
    "plt.plot(iters,map(np.mean,session_rewards))\n",
    "plt.xlabel('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
